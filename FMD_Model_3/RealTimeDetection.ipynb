{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1df8c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import time\n",
    "import cv2\n",
    "import os\n",
    "import imutils\n",
    "from imutils.video import VideoStream\n",
    "from matplotlib import pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ff8b5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "haar_data=cv2.CascadeClassifier('facedetection.xml')\n",
    "#haar_data = cv2.CascadeClassifier(cv2.data.haarcascades + 'facedetection.xml')\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4da492b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading mask detection model which we trained earlier\n",
    "maskNet = load_model(r\"C:\\Users\\lenovo\\ai_proj\\models\\Model3_da\\mobilenet_v2.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fc23e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "capture=cv2.VideoCapture(0)\n",
    "flag,img=capture.read()\n",
    "\n",
    "while True:\n",
    "    flag,img=capture.read()\n",
    "    if flag: \n",
    "        #grey = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        grey = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        faces =haar_data.detectMultiScale(grey,1.3,5)\n",
    "        \n",
    "        for x,y,w,h in faces:            \n",
    "            face= grey[y:y+w,x:x+w]\n",
    "            \n",
    "            #face = cv2.cvtColor(face,cv2.COLOR_GRAY2RGB)   \n",
    "            #face = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            face=cv2.resize(face, (224, 224))\n",
    "            \n",
    "            face = img_to_array(face)\n",
    "            face = preprocess_input(face)\n",
    "            \n",
    "            face= np.expand_dims(face, axis = 0) # need 4th dim\n",
    "            \n",
    "            #face2 = np.array(face, dtype=\"float32\")\n",
    "            \n",
    "            #face=face/255.0\n",
    "            #face=face.reshape(1,224,224,1)\n",
    "            \n",
    "            pred =  pred = maskNet.predict(face)[0] # using our trained model\n",
    "            (mask, withoutMask) = pred\n",
    "            label = \"Mask\" if mask > withoutMask else \"No Mask\"\n",
    "            color = (0, 255, 0) if label == \"Mask\" else (0, 0, 255)\n",
    "        \n",
    "            #result=model.predict(face)\n",
    "            #label=np.argmax(result,axis=1)[0]\n",
    "            \n",
    "            cv2.rectangle(img,(x,y),(x+w,y+h),color,2)\n",
    "            #cv2.rectangle(img,(x,y-40),(x+w,y),color_dict[label],-1)\n",
    "            cv2.putText(img,label,(x,y-10),cv2.FONT_HERSHEY_SIMPLEX, 0.45, color, 2) #(0,0,0)\n",
    "            \n",
    "            cv2.imshow('image',img)\n",
    "            \n",
    "        if cv2.waitKey(2)==ord(\"q\"):\n",
    "            break\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724880fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_course",
   "language": "python",
   "name": "ai_course"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
